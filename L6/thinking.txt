Thinking1：奇异值分解SVD的原理是怎样的，都有哪些应用场景？
A：矩阵A*A^T转化为对称矩阵，进行矩阵分解得到左奇异矩阵和右奇异矩阵以及特征值。
奇异值分解可以通过k来对矩阵降维度，用较少的特征值包含较多的信息。

Thinking2：funkSVD, BiasSVD，SVD++算法之间的区别是怎样的？
A：
funkSVD 避开稀疏问题，而且只用两个矩阵进行相乘，
损失函数=P和Q矩阵乘积得到的评分，与实际用户评分之差，
让损失函数最小化，损失函数上还有正则项防止过拟合。
BiasSVD 用户有自己的偏好(Bias)，比如乐观的用户打分偏高
商品也有自己的偏好(Bias)，比如质量好的商品，打分偏高
将与个性化无关的部分，设置为偏好(Bias)部分。
所以最终的预测值由整体平均数，用户偏好，商品偏好组成，感觉和baseline有点像。
SVD++ 在BiasSVD算法基础上进行了改进，考虑用户的隐式反馈
隐式反馈：没有具体的评分，但可能有点击，浏览等行为。


Thinking3：矩阵分解算法在推荐系统中有哪些应用场景，存在哪些不足
A：SVD分解要求矩阵是稠密的，矩阵中的元素不能有缺失
所以，类似于数据清洗，我们需要先对矩阵中的缺失元素进行补全。
其次，填充方式简单粗暴，会引入很多噪音，误差较大。


Thinking4：item流行度在推荐系统中有怎样的应用
A：首先，item流行度高表明这个item近期是热门事物，在推荐时可以考虑将热门的事物推荐给用户。
其次，item流行度越高，很难反应用户对它的喜爱程度，很多用户是从众心理，当下比较热门的事物，用户就想点开看看，
有k可能本身并不喜欢。所以，对于流行度较低的item可以更能体现出用户的个性喜好。所以在计算相似度后，可以推荐给用户
相似度高的item，但是流行度较低的，这样可续用户会真正的喜欢。

Thinking5：推荐系统的召回阶段都有哪些策略
1、以内容为索引召回。地域、标签、发布时间、点赞数量多的、点击率高等等。
2、以用户为索引召回。近期喜欢看的内容，从内容出发推荐新的相似的新闻，或者找看了这篇新闻的其他用户
还看了哪些内容，用户关注的大V，关注的其他用户近期看的内容等。
3、以设备为索引。根据用户地点对应群体，用户网络对应的群体，机器设备对应的群体，
推荐点击率最高的内容。

